# å·¥ä½œæµç¨‹æ–‡æ¡£

æœ¬æ–‡æ¡£æè¿°å®Œæ•´çš„çˆ¬è™«å·¥ä½œæµç¨‹ï¼Œä»åˆå§‹åŒ–åˆ°æ•°æ®å¯¼å‡ºã€‚

## 1. ç¯å¢ƒå‡†å¤‡

### 1.1 ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- 2GB+ RAM
- 1GB+ ç£ç›˜ç©ºé—´
- ç½‘ç»œè¿æ¥

### 1.2 å®‰è£…æ­¥éª¤

```bash
# å…‹éš†æˆ–ä¸‹è½½ä»£ç 
cd PG533

# è¿è¡Œå®‰è£…è„šæœ¬
./setup.sh

# æˆ–æ‰‹åŠ¨å®‰è£…
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
playwright install chromium
```

### 1.3 é…ç½®

1. å¤åˆ¶é…ç½®æ¨¡æ¿ï¼š
```bash
cp env.example .env
```

2. ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œè°ƒæ•´å‚æ•°ï¼š
```bash
QPS_LIMIT=0.5          # é™ä½ä»¥æ›´ä¿å®ˆ
BURST=2                # å¹¶å‘æ•°
HEADLESS=true          # åå°è¿è¡Œ
ALERT_SINK=...         # Slack webhook (å¯é€‰)
```

## 2. é¦–æ¬¡å®Œæ•´æŠ“å–

### 2.1 æ‰§è¡Œå®Œæ•´æŠ“å–

```bash
# æ¿€æ´»ç¯å¢ƒ
source venv/bin/activate

# è¿è¡Œå®Œæ•´æŠ“å–
python main.py --mode full --headless

# æˆ–ä½¿ç”¨è‡ªå®šä¹‰å‚æ•°
python main.py \
  --mode full \
  --headless \
  --qps 0.3 \
  --burst 1 \
  --data-dir ./data
```

### 2.2 å·¥ä½œæµç¨‹

```
å¯åŠ¨æµè§ˆå™¨
    â†“
è®¿é—®åˆ—è¡¨é¡µ (m.ydl.com/ask)
    â†“
æå– preloadedState
    â†“
è§£æå¸–å­åˆ—è¡¨
    â†“
â”œâ”€â†’ éå†æ¯ä¸ªå¸–å­
â”‚      â†“
â”‚   è®¿é—®è¯¦æƒ…é¡µ
â”‚      â†“
â”‚   æå–å®Œæ•´æ•°æ®ï¼ˆå¸–å­+è¯„è®ºï¼‰
â”‚      â†“
â”‚   åº”ç”¨é™é€Ÿ (QPS)
â”‚      â†“
â”‚   ä¿å­˜åˆ° data/posts/
â”‚      â†“
â”‚   æ›´æ–°æ£€æŸ¥ç‚¹
â”‚      â””â”€â†’ è¿”å›
â”‚
â†“
ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    â†“
å¯¼å‡ºæ•°æ®é›† (dataset.jsonl)
    â†“
å…³é—­æµè§ˆå™¨
```

### 2.3 ç›‘æ§è¾“å‡º

å®æ—¶æ—¥å¿—è¾“å‡ºï¼š

```
2025-11-03T15:30:00 [info] scrape_started mode=full target=https://m.ydl.com/ask
2025-11-03T15:30:01 [info] browser_started
2025-11-03T15:30:02 [info] post_parsed post_id=970141 comments=1
2025-11-03T15:30:04 [info] post_saved post_id=970141 filepath=data/posts/970141_a3b2c1d5.json
...
2025-11-03T15:35:00 [info] scrape_completed posts_count=50
2025-11-03T15:35:01 [info] posts_saved count=48
2025-11-03T15:35:02 [info] dataset_exported path=data/dataset.jsonl
```

### 2.4 é¢„æœŸç»“æœ

```
data/
â”œâ”€â”€ posts/
â”‚   â”œâ”€â”€ 970141_a3b2c1d5.json
â”‚   â”œâ”€â”€ 970140_b4c3d2e6.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ raw/
â”‚   â”œâ”€â”€ 970141_raw.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ checkpoint.json
â”œâ”€â”€ seen_ids.txt
â””â”€â”€ dataset.jsonl

logs/
â””â”€â”€ metrics.jsonl
```

## 3. å¢é‡æ›´æ–°

### 3.1 æ‰§è¡Œå¢é‡æŠ“å–

```bash
# åŸºäºä¸Šæ¬¡æ£€æŸ¥ç‚¹ï¼ŒåªæŠ“å–æ–°å†…å®¹
python main.py --mode incremental --headless
```

### 3.2 å·¥ä½œæµç¨‹

```
åŠ è½½æ£€æŸ¥ç‚¹
    â†“
è¯»å– last_post_id
    â†“
è®¿é—®åˆ—è¡¨é¡µ
    â†“
æå–æ–°å¸–å­ (id > last_post_id)
    â†“
è·³è¿‡å·²æŠ“å–å¸–å­ (åŸºäº seen_ids.txt)
    â†“
ä»…æŠ“å–æ–°å¸–å­è¯¦æƒ…
    â†“
æ›´æ–°æ£€æŸ¥ç‚¹
    â†“
è¿½åŠ åˆ°æ•°æ®é›†
```

### 3.3 è°ƒåº¦ç­–ç•¥

**æ–¹å¼ 1: Cron å®šæ—¶ä»»åŠ¡**

```bash
# æ¯30åˆ†é’Ÿè¿è¡Œä¸€æ¬¡å¢é‡æ›´æ–°
# crontab -e
*/30 * * * * cd /path/to/PG533 && ./venv/bin/python main.py --mode incremental --headless >> logs/cron.log 2>&1
```

**æ–¹å¼ 2: Systemd Timer**

åˆ›å»º `/etc/systemd/system/ydl-scraper.service`:

```ini
[Unit]
Description=YDL Incremental Scraper

[Service]
Type=oneshot
WorkingDirectory=/path/to/PG533
ExecStart=/path/to/PG533/venv/bin/python main.py --mode incremental --headless
User=your_user
```

åˆ›å»º `/etc/systemd/system/ydl-scraper.timer`:

```ini
[Unit]
Description=Run YDL scraper every 30 minutes

[Timer]
OnBootSec=5min
OnUnitActiveSec=30min

[Install]
WantedBy=timers.target
```

å¯ç”¨ï¼š

```bash
sudo systemctl enable ydl-scraper.timer
sudo systemctl start ydl-scraper.timer
```

**æ–¹å¼ 3: Python è„šæœ¬å¾ªç¯**

```python
import asyncio
from datetime import datetime

async def scheduled_scrape():
    while True:
        print(f"Starting scrape at {datetime.now()}")
        # Run main_scrape
        await main_scrape(mode="incremental")
        
        # Wait 30 minutes
        await asyncio.sleep(1800)

asyncio.run(scheduled_scrape())
```

## 4. æ•°æ®å¤„ç†æµç¨‹

### 4.1 å»é‡æœºåˆ¶

```python
# 1. åŸºäºå†…å®¹çš„ SHA1 æŒ‡çº¹
unique_id = sha1(f"{post_id}_{content[:100]}_{publish_time}")

# 2. æ£€æŸ¥ seen_ids.txt
if unique_id in seen_ids:
    skip()

# 3. ä¿å­˜æ—¶è®°å½•
seen_ids.add(unique_id)
```

### 4.2 æ•°æ®éªŒè¯

æ¯ä¸ªå¸–å­ä¿å­˜å‰è‡ªåŠ¨éªŒè¯ï¼š

- âœ… å¿…éœ€å­—æ®µå­˜åœ¨
- âœ… æ•°æ®ç±»å‹æ­£ç¡®
- âœ… å…³ç³»å®Œæ•´ï¼ˆè¯„è®ºå…³è”åˆ°å¸–å­ï¼‰
- âœ… URL å¯è®¿é—®
- âœ… æ—¶é—´æ ¼å¼æœ‰æ•ˆ

### 4.3 é”™è¯¯å¤„ç†

```
è¯·æ±‚å¤±è´¥
    â†“
é‡è¯• (æœ€å¤š3æ¬¡)
    â†“
æŒ‡æ•°é€€é¿ (1s â†’ 2s â†’ 4s)
    â†“
ä»å¤±è´¥ï¼Ÿ
    â†“
è®°å½•é”™è¯¯
    â†“
å‘é€å‘Šè­¦ (å¦‚é…ç½®)
    â†“
ç»§ç»­ä¸‹ä¸€ä¸ª
```

## 5. ç›‘æ§ä¸å‘Šè­¦

### 5.1 å¥åº·æ£€æŸ¥

è‡ªåŠ¨æ£€æµ‹å¼‚å¸¸å¹¶å‘Šè­¦ï¼š

| æ¡ä»¶ | ä¸¥é‡ç¨‹åº¦ | åŠ¨ä½œ |
|------|---------|------|
| æˆåŠŸç‡ < 50% | Critical | ç«‹å³å‘Šè­¦ + åœæ­¢ |
| æˆåŠŸç‡ < 80% | Warning | å‘é€å‘Šè­¦ |
| é‡åˆ° 403/429 | Critical | ç«‹å³å‘Šè­¦ + åœæ­¢ |
| ç©ºé¡µ > 5 | Warning | å‘é€å‘Šè­¦ |
| é”™è¯¯ç‡ > 10% | Warning | å‘é€å‘Šè­¦ |

### 5.2 å®æ—¶æŒ‡æ ‡

```json
{
  "timestamp": "2025-11-03T15:30:00",
  "total_posts": 50,
  "total_comments": 125,
  "errors": 2,
  "success_rate": 96.0,
  "duration_seconds": 300,
  "http_status_codes": {
    "200": 48,
    "404": 2
  }
}
```

### 5.3 å‘Šè­¦ç¤ºä¾‹

**Slack é€šçŸ¥**:

```
ğŸ”” INFO: Scraping completed: 48 posts
  â€¢ mode: incremental
  â€¢ posts: 48
  â€¢ success_rate: 96.0%
```

**Critical å‘Šè­¦**:

```
ğŸ”¥ CRITICAL: Access restricted - possible rate limiting
  â€¢ http_codes: {"403": 5, "429": 2}
```

## 6. æ•°æ®å¯¼å‡ºä¸åˆ†æ

### 6.1 å¯¼å‡ºæ ¼å¼

**JSONL (é»˜è®¤)**:

```bash
python main.py --export-only
# è¾“å‡º: data/dataset.jsonl
```

æ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼Œé€‚åˆæµå¼å¤„ç†ï¼š

```jsonl
{"post_id": 970141, "username": "...", "content": "...", "comments": [...]}
{"post_id": 970140, "username": "...", "content": "...", "comments": [...]}
```

**CSV (è‡ªå®šä¹‰)**:

```python
import json
import csv

posts = []
with open('data/dataset.jsonl') as f:
    for line in f:
        posts.append(json.loads(line))

with open('posts.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.DictWriter(f, fieldnames=['post_id', 'username', 'content', ...])
    writer.writeheader()
    for post in posts:
        writer.writerow({
            'post_id': post['post_id'],
            'username': post['username'],
            'content': post['content'],
            # ...
        })
```

### 6.2 æ•°æ®åˆ†æç¤ºä¾‹

**ç»Ÿè®¡åˆ†æ**:

```python
import json
from collections import Counter

posts = []
with open('data/dataset.jsonl') as f:
    for line in f:
        posts.append(json.loads(line))

# ç”¨æˆ·æ´»è·ƒåº¦
user_counts = Counter(p['username'] for p in posts)
print("Top 10 active users:", user_counts.most_common(10))

# è¯é¢˜åˆ†å¸ƒ
topic_counts = Counter(p['topic_title'] for p in posts if p['topic_title'])
print("Popular topics:", topic_counts.most_common(10))

# è¯„è®ºç»Ÿè®¡
avg_comments = sum(len(p['comments']) for p in posts) / len(posts)
print(f"Average comments per post: {avg_comments:.2f}")
```

## 7. æ•…éšœæ¢å¤

### 7.1 ä¸­æ–­æ¢å¤

çˆ¬è™«æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼š

1. æ£€æŸ¥ç‚¹æ¯æ¬¡æŠ“å–åè‡ªåŠ¨ä¿å­˜
2. ä¸­æ–­åé‡æ–°è¿è¡Œï¼Œè‡ªåŠ¨ä»ä¸Šæ¬¡ä½ç½®ç»§ç»­
3. å·²æŠ“å–æ•°æ®ä¸ä¼šé‡å¤

```bash
# å³ä½¿ä¸­é€” Ctrl+Cï¼Œæ•°æ®ä¹Ÿå·²ä¿å­˜
python main.py --mode incremental
# ... ä¸­æ–­ ...

# é‡æ–°è¿è¡Œï¼Œè‡ªåŠ¨ç»§ç»­
python main.py --mode incremental
```

### 7.2 æ•°æ®æ¢å¤

å¦‚æœ `checkpoint.json` æŸåï¼š

```bash
# æ‰‹åŠ¨é‡å»ºæ£€æŸ¥ç‚¹
python -c "
import json
from pathlib import Path

posts = sorted(Path('data/posts').glob('*.json'))
if posts:
    last_post = json.loads(posts[-1].read_text())
    checkpoint = {
        'last_post_id': last_post['post_id'],
        'last_post_time': last_post['publish_time'],
        'total_posts_scraped': len(posts)
    }
    Path('data/checkpoint.json').write_text(json.dumps(checkpoint, indent=2))
    print('Checkpoint rebuilt!')
"
```

### 7.3 æ—¥å¿—åˆ†æ

æŸ¥çœ‹é”™è¯¯æ—¥å¿—ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰é”™è¯¯
grep "error" logs/metrics.jsonl

# ç»Ÿè®¡ HTTP çŠ¶æ€ç 
jq -r '.http_status_codes' logs/metrics.jsonl | jq -s 'add'

# æŸ¥çœ‹æˆåŠŸç‡è¶‹åŠ¿
jq -r '[.timestamp, .success_rate] | @csv' logs/metrics.jsonl
```

## 8. æœ€ä½³å®è·µ

### 8.1 ç”Ÿäº§ç¯å¢ƒé…ç½®

```bash
# .env for production
QPS_LIMIT=0.3          # æ›´ä¿å®ˆ
BURST=1                # å•çº¿ç¨‹
RETRY=5                # æ›´å¤šé‡è¯•
HEADLESS=true          # åå°è¿è¡Œ
ALERT_SINK=...         # å¿…é¡»é…ç½®å‘Šè­¦
```

### 8.2 ç›‘æ§æ£€æŸ¥æ¸…å•

- [ ] é…ç½® Slack/Discord å‘Šè­¦
- [ ] è®¾ç½® Cron å®šæ—¶ä»»åŠ¡
- [ ] ç›‘æ§ç£ç›˜ç©ºé—´ (`df -h`)
- [ ] å®šæœŸæ£€æŸ¥æ—¥å¿— (`tail -f logs/metrics.jsonl`)
- [ ] éªŒè¯æ•°æ®è´¨é‡ï¼ˆæŠ½æ ·æ£€æŸ¥ï¼‰
- [ ] å¤‡ä»½æ•°æ®åˆ°äº‘å­˜å‚¨

### 8.3 æ€§èƒ½ä¼˜åŒ–

**å¦‚æœæŠ“å–å¤ªæ…¢**:

1. é€‚å½“æé«˜ QPSï¼ˆé£é™©ï¼šå¯èƒ½è¢«é™æµï¼‰
2. å¢åŠ  BURSTï¼ˆé£é™©ï¼šå¹¶å‘è¿‡å¤šå¯èƒ½è§¦å‘ä¿æŠ¤ï¼‰
3. ä½¿ç”¨å¤šå°æœºå™¨åˆ†å¸ƒå¼æŠ“å–
4. ä»…æŠ“å–å…³é”®å­—æ®µï¼Œè·³è¿‡ä¸é‡è¦æ•°æ®

**å¦‚æœè¢«é™æµ**:

1. ç«‹å³é™ä½ QPS (`--qps 0.2`)
2. å¢åŠ é€€é¿æ—¶é—´
3. æ›´æ¢ IPï¼ˆä½¿ç”¨ä»£ç†æ± ï¼‰
4. æš‚åœä¸€æ®µæ—¶é—´åæ¢å¤

### 8.4 æ•°æ®è´¨é‡ä¿è¯

```bash
# å®šæœŸéªŒè¯æ•°æ®
python -c "
import json
from pathlib import Path

posts = Path('data/posts').glob('*.json')
issues = []

for post_file in posts:
    post = json.loads(post_file.read_text())
    
    # æ£€æŸ¥å¿…éœ€å­—æ®µ
    if not post.get('post_id'):
        issues.append(f'{post_file}: missing post_id')
    if not post.get('content'):
        issues.append(f'{post_file}: missing content')
    
    # æ£€æŸ¥è¯„è®ºå®Œæ•´æ€§
    for comment in post.get('comments', []):
        if not comment.get('comment_content'):
            issues.append(f'{post_file}: comment missing content')

if issues:
    print('Issues found:')
    for issue in issues[:10]:
        print(f'  - {issue}')
else:
    print('âœ… All data validated!')
"
```

## 9. å¸¸è§ä½¿ç”¨åœºæ™¯

### åœºæ™¯ 1: æ¯æ—¥æ•°æ®åŒæ­¥

```bash
#!/bin/bash
# daily_sync.sh

cd /path/to/PG533
source venv/bin/activate

# å¢é‡æŠ“å–
python main.py --mode incremental --headless

# å¯¼å‡ºåˆ°äº‘å­˜å‚¨
aws s3 sync data/ s3://my-bucket/ydl-data/$(date +%Y-%m-%d)/

# ç”Ÿæˆæ—¥æŠ¥
python -c "
import json
posts = []
with open('data/dataset.jsonl') as f:
    for line in f:
        posts.append(json.loads(line))

print(f'Total posts: {len(posts)}')
print(f'Today: {sum(1 for p in posts if \"ä»Šå¤©\" in p[\"publish_time\"])}')
"
```

### åœºæ™¯ 2: å…³é”®è¯ç›‘æ§

```bash
# ç›‘æ§ç‰¹å®šå…³é”®è¯çš„å¸–å­
python -c "
import json

keywords = ['ç„¦è™‘', 'æŠ‘éƒ', 'å‹åŠ›']

with open('data/dataset.jsonl') as f:
    for line in f:
        post = json.loads(line)
        if any(kw in post['content'] for kw in keywords):
            print(f'{post[\"post_id\"]}: {post[\"content\"][:50]}...')
"
```

### åœºæ™¯ 3: ç”¨æˆ·è¡Œä¸ºåˆ†æ

```python
import json
from datetime import datetime

users = {}

with open('data/dataset.jsonl') as f:
    for line in f:
        post = json.loads(line)
        username = post['username']
        
        if username not in users:
            users[username] = {
                'posts': 0,
                'comments_received': 0,
                'topics': set()
            }
        
        users[username]['posts'] += 1
        users[username]['comments_received'] += len(post['comments'])
        if post.get('topic_title'):
            users[username]['topics'].add(post['topic_title'])

# æ‰¾å‡ºæœ€æ´»è·ƒç”¨æˆ·
top_users = sorted(users.items(), key=lambda x: x[1]['posts'], reverse=True)[:10]

for username, stats in top_users:
    print(f"{username}: {stats['posts']} posts, {stats['comments_received']} comments")
```

---

**æŒç»­æ”¹è¿›**: æœ¬å·¥ä½œæµç¨‹ä¼šæ ¹æ®å®é™…ä½¿ç”¨ç»éªŒä¸æ–­ä¼˜åŒ–ã€‚æ¬¢è¿æäº¤æ”¹è¿›å»ºè®®ï¼

